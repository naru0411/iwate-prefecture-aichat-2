# RAG チャットボット 

Llama.cpp (Qwen2.5) を使用し、大学公式サイトの情報を元に回答するローカルRAGシステム。

## 🌟 主な特徴

- **厳格なハルシネーション対策 (Spartan Mode)**
  - **日付矛盾検知**: 「10月下旬（1月26日）」のような矛盾した日付や、「9月...1月」といった離れた月が混在する場合、情報の混同とみなして回答を自動的にブロック（Fallback）します。
  - **固有名詞保護**: 「ソフトウェア」を「软件」とするような誤変換を強制排除し、大学独自の名称を正確に維持します。
  - **推論禁止指示**: 資料に記載のない情報の組み合わせや推測を禁止する厳格なシステムプロンプトを採用。

- **高精度なデータ検索 (High-Resolution RAG)**
  - **チャンクサイズ最適化 (250)**: 検索単位を250文字に絞ることで、異なる学部の情報が1つの回答に混ざるリスクを最小化しています。
  - **Window Retrieval**: 検索ヒット箇所の前後500文字を含めたコンテキストをモデルに渡すことで、文脈の理解を深めています。

- **物理ドライブ・絶対パス運用**
  - プロジェクトの肥大化を防ぐため、LLMモデルやベクトルデータ（embeddings）を外部ドライブで一元管理する設計です。

- **使いやすいUI/UX**
  - **マルチセッション履歴**: ChatGPT風のサイドバーで、複数のチャット履歴を管理可能（タイトル変更・削除対応）。
  - **自動スクレイピング**: 初回起動時に大学サイト（約133ページ）を自動でクロールし、知識ベースを構築します。

## 🛠️ 技術スタック

- **Language**: Python 3.10
- **LLM**: Qwen2.5-1.5B-Instruct-GGUF (Llama-cpp-python)
- **Embeddings**: intfloat/multilingual-e5-small (Sentence-Transformers)
- **UI**: Streamlit

## 🚀 セットアップと起動

### 1. 初回セットアップ
`setup.bat` を実行してください。仮想環境（venv）の作成と、必要なライブラリのインストールが自動で行われます。

### 2. アプリの起動
`run.bat` を実行してください。
- 初回起動時は、モデルのダウンロードとWebスクレイピングが行われるため、数分〜数十分程度時間がかかります。
- 知識ベースが構築されると、次回以降は高速に起動します。

## 📁 フォルダ構成
- `core.py`: RAGエンジンのコアロジック（検索・生成・ハルシネーション対策）。
- `app.py`: Streamlit によるWebインターフェース・履歴管理。
- `storage/`: ベクトルデータベース（Eドライブにリダイレクト設定）。

## ⚠️ 注意事項
- **ストリーミング無効化**: 回答の事後検証（日付矛盾チェック等）を確実に行うため、ストリーミング表示は無効化されています。
- **再構築**: 検索アルゴリズムの大幅な変更時には、`storage` フォルダを削除してデータの再取得を行う必要があります。

## ライセンス

[MIT License](LICENSE)

---
Developed for Iwate Prefectural University Support.
